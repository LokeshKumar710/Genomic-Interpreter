# -*- coding: utf-8 -*-
"""Untitled6.ipynb

Automatically generated by Colaboratory.

Original file is located at
    https://colab.research.google.com/drive/1LBKb_ah_MGDi6jAjmc5hgMLoAFbUqfR7
"""

pip install git+https://github.com/Zehui127/1d-swin

from swin1d.module import swin_1d_block
from swin1d.examples import (
    random_text_generator,
    generate_random_dna,
    onehot_encoder,
)


def test_genomic_model(seq_length=512):
    """The input is a random DNA sequence generator, which generates a random
    DNA sequence with length of seq_length. The output is a tensor with shape
    of (batch_size, seq_length//block_num, hidden_size*block_num)."""

    input = generate_random_dna(seq_length)
    encode_input = onehot_encoder(input)
    model = swin1d_block(4)
    output = model(encode_input)
    print(output.shape)
    return output


def test_language_model(seq_length=512):
    """The input is a random text generator, which generates a random text with
    length of seq_length. The output is a tensor with shape of
    (batch_size, seq_length//block_num, input_token_size*block_num)."""

    input = random_text_generator(2, seq_length, tokenized=True)
    model = swin1d_block(1)
    output = model(input)
    print(output.shape)
    return output


def swin1d_block(dim):
    # stage = (number layers in each swin,
    #          whether to merge the ouput of each swin,
    #          window size)

    window_size = 32
    stages = [
        (
            4,
            True,
            window_size,
        ),
        (
            2,
            False,
            window_size,
        ),
        (
            2,
            False,
            window_size,
        ),
        (
            2,
            False,
            window_size,
        ),
    ]
    model = swin_1d_block(stages, dim)
    return model

import torch
import random
import numpy as np


def generate_random_dna(length=32):
    dna = ""
    for i in range(length):
        dna += random.choice(["A", "T", "G", "C"])
    return [dna]
print(generate_random_dna(32))

def onehot_encoder(sequences):
    max_len = max([len(s) for s in sequences])
    dictionary = {
        "A": [1, 0, 0, 0],
        "T": [0, 1, 0, 0],
        "G": [0, 0, 1, 0],
        "C": [0, 0, 0, 1],
    }
    if not isinstance(sequences, (list, tuple, np.ndarray)):
        sequences = list(sequences)
    for i in range(len(sequences)):
        sequences[i] = sequences[i].upper()[:max_len]
    shape = [len(sequences), max_len, len(dictionary)]
    onehot = np.zeros(shape, dtype=np.float32)
    for i, s in enumerate(sequences):
        for j, el in enumerate(s):
            onehot[i, j] = dictionary[el]
    if len(sequences) == 1:
        onehot = np.squeeze(onehot, axis=0)
    return torch.tensor(onehot).unsqueeze(0)


def dna_decoder(dna):
    dictionary = {
        0: "A",
        1: "T",
        2: "G",
        3: "C",
    }
    return "".join([dictionary[torch.argmax(j).item()] for j in dna])

from transformers import GPT2Tokenizer
import torch
import random
import numpy as np

tokenizer = GPT2Tokenizer.from_pretrained("gpt2")
WORDS_BANK = [
    "you",
    "I",
    "me",
    "he",
    "she",
    "him",
    "they",
    "them",
    "love",
    "take",
    "seek",
    "buy",
    "dream",
    "eat",
    "play",
    "beat",
    "drink",
    "cat",
    "dog",
    "tiger",
    "chicken",
    "beef",
    "milk",
    "juice",
    "water",
    "police",
    "student",
    "teacher",
    "airplane",
    "train",
    "car",
    ",",
    ".",
    ":",
    "but",
    "and",
]
WORDS_COUNT = len(WORDS_BANK)


def tokenize(text, max_seq_length=32):
    # Tokenize the input text
    tokenized_input = tokenizer.encode(text, add_special_tokens=False)
    print(tokenized_input)

    # Pad or truncate the input sequence to the desired length
    padded_input = tokenized_input[:max_seq_length] + [
        tokenizer.pad_token_id
    ] * (max_seq_length - len(tokenized_input))

    # Convert the input sequence to tensors
    np_padded_input = np.array(padded_input, dtype=float)
    input_ids = torch.tensor(np_padded_input, dtype=torch.float32)

    return input_ids


def random_text_generator(batch_size, seq_length=WORDS_COUNT, tokenized=False):
    def generate_sentence(seq_length):
        return " ".join(
            WORDS_BANK[random.randint(0, WORDS_COUNT - 1)]
            for _ in range(seq_length)
        )

    # return a list of sentences
    # choose seq_length words from word bank
    shape = [batch_size, seq_length, 1]
    res = np.zeros(shape, dtype=np.float32)
    if tokenized:
        for i in range(batch_size):
            res[i] = tokenize(
                generate_sentence(seq_length), seq_length
            ).unsqueeze(1)
        return torch.tensor(res)
    else:
        return [generate_sentence(seq_length) for _ in range(batch_size)]


def text_decoder(input_ids):
    text = tokenizer.decode(input_ids, skip_special_tokens=True)
    return text
print(len(WORDS_BANK))
print(random_text_generator(10,len(WORDS_BANK),False))
k=random_text_generator(10,len(WORDS_BANK),False)
print(len(k))
print()
print("batch1")
print(k[0])
print('batch2')
print(k[1])

__all__ = [
    "tokenize",
    "random_text_generator",
    "text_decoder",
    "generate_random_dna",
    "onehot_encoder",
    "dna_decoder",
]

from swin1d.module import swin_1d_block
from swin1d.examples import (
    random_text_generator,
    generate_random_dna,
    onehot_encoder,
)


def test_genomic_model(seq_length=512):
    input = generate_random_dna(seq_length)
    encode_input = onehot_encoder(input)
    model = swin1d_block(4)
    output = model(encode_input)
    print(output.shape)
    return output


def test_language_model(seq_length=512):
    input = random_text_generator(2, seq_length, tokenized=True)
    model = swin1d_block(1)
    output = model(input)
    print(output.shape)
    return output
print(test_language_model(512))

def swin1d_block(dim):
    # stage = (number layers in each swin,
    #          whether to merge the ouput of each swin,
    #          window size)

    window_size = 32
    stages = [
        (
            4,
            True,
            window_size,
        ),
        (
            2,
            False,
            window_size,
        ),
        (
            2,
            False,
            window_size,
        ),
        (
            2,
            False,
            window_size,
        ),
    ]
    model = swin_1d_block(stages, dim)
    return model


if __name__ == "__main__":
    test_genomic_model()

print(test_language_model)

